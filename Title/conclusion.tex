


The proposed SleepGCN-Transformer architecture demonstrates superior performance in sleep stage classification, achieving 93.12\% training accuracy and 93.04\% validation accuracy. By integrating GCNs to model spatial interdependencies and Transformers to extract temporal patterns, the model effectively captures the complexity of sleep physiology. The application of Focal Loss contributes to robust handling of class imbalance, improving classification across all stages. Feature importance analysis indicates that EMG and the EEG Pz-Oz channel play a critical role in prediction. This approach not only improves predictive performance but also enhances interpretability, laying a foundation for future work in explainable and clinically applicable sleep analysis tools.
