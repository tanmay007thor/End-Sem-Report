

Our proposed SleepGCN-Transformer model achieves 93.12\% training accuracy and
93.04\% validation accuracy, demonstrating its effectiveness in sleep stage classification.
The integration of Graph Convolution Networks (GCN) captures spatial dependencies
across EEG, EOG, and EMG channels, while the Transformer extracts temporal patterns. The
use of Focal Loss enhances class balancing, improving performance on underrepresented sleep
stages. Feature importance analysis highlights EMG and EEG Pz-Oz as key predictors. This
robust approach lays the foundation for future work in Explainable AI, enabling medical
professionals to interpret AI-driven sleep diagnostics effectively.