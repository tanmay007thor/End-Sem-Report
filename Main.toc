\babel@toc {english}{}\relax 
\contentsline {chapter}{Contents}{v}{Doc-Start}%
\contentsline {chapter}{List of Figures}{vi}{chapter*.1}%
\contentsline {chapter}{List of Tables}{vii}{chapter*.2}%
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\contentsline {chapter}{\numberline {2}Literature Review}{4}{chapter.2}%
\contentsline {chapter}{\numberline {3}SleepGCN-Transformer Hybrid Graph Convolution and Transfomer Network Methodology}{6}{chapter.3}%
\contentsline {section}{\numberline {3.1}Methodology}{6}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Input Data and Preprocessing}{7}{subsection.3.1.1}%
\contentsline {subsubsection}{Sleep Stage Mapping}{7}{subsection.3.1.1}%
\contentsline {subsubsection}{Channel Selection}{8}{table.caption.7}%
\contentsline {subsubsection}{Preprocessing}{8}{table.caption.7}%
\contentsline {subsection}{\numberline {3.1.2}Graph Construction}{9}{subsection.3.1.2}%
\contentsline {subsubsection}{Methodology: Graph Dataset Creation}{9}{subsection.3.1.2}%
\contentsline {subsubsection}{Graph Representation of EEG Channels}{10}{table.caption.9}%
\contentsline {subsection}{\numberline {3.1.3}GCN Layers for Spatial Feature Extraction}{10}{subsection.3.1.3}%
\contentsline {subsection}{\numberline {3.1.4}Transformer Encoder for Temporal Dependencies}{12}{subsection.3.1.4}%
\contentsline {subsection}{\numberline {3.1.5}Loss Function and Optimization}{14}{subsection.3.1.5}%
\contentsline {subsubsection}{Why Focal Loss Instead of Standard Cross-Entropy?}{14}{subsection.3.1.5}%
\contentsline {subsubsection}{Focal Loss Formulation}{15}{subsection.3.1.5}%
\contentsline {subsubsection}{Implementation Details}{15}{subsection.3.1.5}%
\contentsline {subsubsection}{Why Use a Learning Rate Scheduler?}{15}{subsection.3.1.5}%
\contentsline {subsubsection}{Cosine Annealing Learning Rate Decay}{16}{subsection.3.1.5}%
\contentsline {subsubsection}{Training Methodology: Overview}{17}{subsection.3.1.5}%
\contentsline {subsubsection}{Training Methodology: Hyperparameters}{17}{subsection.3.1.5}%
\contentsline {subsubsection}{Training Methodology: Handling Class Imbalance}{18}{subsection.3.1.5}%
\contentsline {chapter}{\numberline {4}Results and Discussion}{19}{chapter.4}%
\contentsline {subsection}{\numberline {4.0.1}Testing Data Distribution Analysis}{19}{subsection.4.0.1}%
\contentsline {subsection}{\numberline {4.0.2}Model Performance: Training vs Testing}{19}{subsection.4.0.2}%
\contentsline {subsection}{\numberline {4.0.3}Model Evaluation: Confusion Matrix}{21}{subsection.4.0.3}%
\contentsline {subsection}{\numberline {4.0.4}Gradient Analysis: Training Progression}{21}{subsection.4.0.4}%
\contentsline {subsection}{\numberline {4.0.5}Performance Metrics: Precision, Recall, F1-Score}{22}{subsection.4.0.5}%
\contentsline {subsection}{\numberline {4.0.6}Feature Importance Analysis with LIME}{24}{subsection.4.0.6}%
\contentsline {chapter}{\numberline {5}Conclusion}{26}{chapter.5}%
\contentsline {chapter}{\numberline {6}Reference}{27}{chapter.6}%
